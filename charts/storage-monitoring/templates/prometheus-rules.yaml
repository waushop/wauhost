---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: {{ include "storage-monitoring.fullname" . }}-rules
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "storage-monitoring.labels" . | nindent 4 }}
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    - name: longhorn.rules
      interval: 30s
      rules:
        # Volume Space Alerts
        - alert: LonghornVolumeActualSpaceUsedWarning
          expr: (longhorn_volume_actual_size_bytes / longhorn_volume_capacity_bytes) > 0.8
          for: 5m
          labels:
            severity: warning
            component: longhorn
          annotations:
            summary: "Longhorn volume {{ "{{ $labels.volume }}" }} space usage warning"
            description: "Volume {{ "{{ $labels.volume }}" }} is using {{ "{{ $value | humanizePercentage }}" }} of its capacity"
            runbook_url: "https://longhorn.io/docs/troubleshooting/volume-space/"

        - alert: LonghornVolumeActualSpaceUsedCritical
          expr: (longhorn_volume_actual_size_bytes / longhorn_volume_capacity_bytes) > 0.95
          for: 5m
          labels:
            severity: critical
            component: longhorn
          annotations:
            summary: "Longhorn volume {{ "{{ $labels.volume }}" }} space usage critical"
            description: "Volume {{ "{{ $labels.volume }}" }} is using {{ "{{ $value | humanizePercentage }}" }} of its capacity"
            runbook_url: "https://longhorn.io/docs/troubleshooting/volume-space/"

        # Node Storage Alerts
        - alert: LonghornNodeStorageWarning
          expr: (longhorn_node_storage_usage_bytes / longhorn_node_storage_capacity_bytes) > 0.7
          for: 5m
          labels:
            severity: warning
            component: longhorn
          annotations:
            summary: "Longhorn node {{ "{{ $labels.node }}" }} storage warning"
            description: "Node {{ "{{ $labels.node }}" }} is using {{ "{{ $value | humanizePercentage }}" }} of storage capacity"

        - alert: LonghornNodeStorageCritical
          expr: (longhorn_node_storage_usage_bytes / longhorn_node_storage_capacity_bytes) > 0.85
          for: 5m
          labels:
            severity: critical
            component: longhorn
          annotations:
            summary: "Longhorn node {{ "{{ $labels.node }}" }} storage critical"
            description: "Node {{ "{{ $labels.node }}" }} is using {{ "{{ $value | humanizePercentage }}" }} of storage capacity"

        # Volume Health Alerts
        - alert: LonghornVolumeStatusCritical
          expr: longhorn_volume_robustness == 3
          for: 5m
          labels:
            severity: critical
            component: longhorn
          annotations:
            summary: "Longhorn volume {{ "{{ $labels.volume }}" }} is Faulted"
            description: "Volume {{ "{{ $labels.volume }}" }} is in Faulted state - immediate action required"

        - alert: LonghornVolumeStatusDegraded
          expr: longhorn_volume_robustness == 2
          for: 5m
          labels:
            severity: warning
            component: longhorn
          annotations:
            summary: "Longhorn volume {{ "{{ $labels.volume }}" }} is Degraded"
            description: "Volume {{ "{{ $labels.volume }}" }} is in Degraded state - replicas may be unavailable"

        # Backup Alerts
        - alert: LonghornBackupFailed
          expr: increase(longhorn_backup_error_total[1h]) > 0
          for: 5m
          labels:
            severity: warning
            component: longhorn
          annotations:
            summary: "Longhorn backup errors detected"
            description: "{{ "{{ $value }}" }} backup errors in the last hour"

        - alert: LonghornBackupStale
          expr: time() - longhorn_backup_last_completed_at > 86400
          for: 1h
          labels:
            severity: warning
            component: longhorn
          annotations:
            summary: "Longhorn backup is stale"
            description: "No successful backup completed in the last 24 hours"

        # Node Alerts
        - alert: LonghornNodeDown
          expr: longhorn_node_status == 0
          for: 5m
          labels:
            severity: critical
            component: longhorn
          annotations:
            summary: "Longhorn node {{ "{{ $labels.node }}" }} is down"
            description: "Node {{ "{{ $labels.node }}" }} has been down for more than 5 minutes"

    - name: minio.rules
      interval: 30s
      rules:
        # Disk Alerts
        - alert: MinioClusterDiskOffline
          expr: minio_cluster_disk_offline_total > 0
          for: 5m
          labels:
            severity: critical
            component: minio
          annotations:
            summary: "MinIO cluster has offline disks"
            description: "{{ "{{ $value }}" }} disks are offline in MinIO cluster"

        # Storage Usage Alerts
        - alert: MinioBucketUsageHigh
          expr: |
            (sum(minio_bucket_usage_total_bytes) by (instance) /
            ({{ .Values.monitoring.minio.totalStorage | default "100" }} * 1024 * 1024 * 1024)) > 0.8
          for: 5m
          labels:
            severity: warning
            component: minio
          annotations:
            summary: "MinIO storage usage high"
            description: "MinIO is using {{ "{{ $value | humanizePercentage }}" }} of total storage"

        - alert: MinioBucketUsageCritical
          expr: |
            (sum(minio_bucket_usage_total_bytes) by (instance) /
            ({{ .Values.monitoring.minio.totalStorage | default "100" }} * 1024 * 1024 * 1024)) > 0.95
          for: 5m
          labels:
            severity: critical
            component: minio
          annotations:
            summary: "MinIO storage usage critical"
            description: "MinIO is using {{ "{{ $value | humanizePercentage }}" }} of total storage"

        # Performance Alerts
        - alert: MinioHighLatency
          expr: histogram_quantile(0.99, rate(minio_http_requests_duration_seconds_bucket[5m])) > 1
          for: 5m
          labels:
            severity: warning
            component: minio
          annotations:
            summary: "MinIO high request latency"
            description: "99th percentile latency is {{ "{{ $value }}" }}s"

        - alert: MinioHighErrorRate
          expr: |
            sum(rate(minio_http_requests_4xx_errors_total[5m])) > 10 or
            sum(rate(minio_http_requests_5xx_errors_total[5m])) > 5
          for: 5m
          labels:
            severity: warning
            component: minio
          annotations:
            summary: "MinIO high error rate"
            description: "MinIO is experiencing high error rates"

        # Service Availability
        - alert: MinioDown
          expr: up{job="minio"} == 0
          for: 5m
          labels:
            severity: critical
            component: minio
          annotations:
            summary: "MinIO is down"
            description: "MinIO service has been down for more than 5 minutes"

        # Healing Operations
        - alert: MinioHealingOperations
          expr: minio_heal_objects_total > 0
          for: 15m
          labels:
            severity: warning
            component: minio
          annotations:
            summary: "MinIO healing operations ongoing"
            description: "MinIO has been healing {{ "{{ $value }}" }} objects for more than 15 minutes"

    - name: backup.rules
      interval: 30s
      rules:
        # Backup Job Alerts
        - alert: BackupJobFailed
          expr: |
            kube_job_status_failed{job_name=~".*backup.*"} > 0
          for: 5m
          labels:
            severity: critical
            component: backup
          annotations:
            summary: "Backup job {{ "{{ $labels.job_name }}" }} failed"
            description: "Backup job {{ "{{ $labels.job_name }}" }} has failed"

        - alert: BackupJobNotScheduled
          expr: |
            time() - kube_cronjob_next_schedule_time{cronjob=~".*backup.*"} > 3600
          for: 1h
          labels:
            severity: warning
            component: backup
          annotations:
            summary: "Backup job {{ "{{ $labels.cronjob }}" }} not scheduled"
            description: "Backup cronjob {{ "{{ $labels.cronjob }}" }} hasn't been scheduled for over an hour"

        # Backup Age Alerts
        - alert: BackupTooOld
          expr: |
            (time() - backup_last_successful_timestamp) > 86400
          for: 1h
          labels:
            severity: warning
            component: backup
          annotations:
            summary: "Backup for {{ "{{ $labels.backup_type }}" }} is too old"
            description: "Last successful backup was {{ "{{ $value | humanizeDuration }}" }} ago"

    - name: storage.general
      interval: 30s
      rules:
        # PVC Alerts
        - alert: PersistentVolumeClaimPending
          expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} > 0
          for: 15m
          labels:
            severity: warning
            component: storage
          annotations:
            summary: "PVC {{ "{{ $labels.namespace }}" }}/{{ "{{ $labels.persistentvolumeclaim }}" }} is pending"
            description: "PVC has been pending for more than 15 minutes"

        - alert: PersistentVolumeClaimLost
          expr: kube_persistentvolumeclaim_status_phase{phase="Lost"} > 0
          for: 5m
          labels:
            severity: critical
            component: storage
          annotations:
            summary: "PVC {{ "{{ $labels.namespace }}" }}/{{ "{{ $labels.persistentvolumeclaim }}" }} is lost"
            description: "PVC is in Lost state - data may be inaccessible"

        # Storage Class Alerts
        - alert: StorageClassUnavailable
          expr: |
            kube_storageclass_info == 0
          for: 5m
          labels:
            severity: critical
            component: storage
          annotations:
            summary: "Storage class {{ "{{ $labels.storageclass }}" }} unavailable"
            description: "Storage class is not available for provisioning"

    - name: database.rules
      interval: 30s
      rules:
        # MySQL Alerts
        - alert: MySQLDown
          expr: mysql_up == 0
          for: 5m
          labels:
            severity: critical
            component: mysql
          annotations:
            summary: "MySQL is down"
            description: "MySQL instance {{ "{{ $labels.instance }}" }} has been down for more than 5 minutes"

        - alert: MySQLTooManyConnections
          expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections > 0.8
          for: 5m
          labels:
            severity: warning
            component: mysql
          annotations:
            summary: "MySQL too many connections"
            description: "MySQL is using {{ "{{ $value | humanizePercentage }}" }} of max connections"

        - alert: MySQLSlowQueries
          expr: rate(mysql_global_status_slow_queries[5m]) > 0.05
          for: 5m
          labels:
            severity: warning
            component: mysql
          annotations:
            summary: "MySQL slow queries detected"
            description: "MySQL is executing {{ "{{ $value }}" }} slow queries per second"
